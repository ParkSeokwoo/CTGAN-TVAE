{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/train.csv')\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/sample_submission.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/test.csv')"
      ],
      "metadata": {
        "id": "ADVW1SGVHczp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "hR8oCcXPySii",
        "outputId": "65d3c4b3-c3f5-4489-e293-0f86e9e6baee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index gender car reality  child_num  income_total           income_type  \\\n",
              "0      0      F   N       N          0      202500.0  Commercial associate   \n",
              "1      1      F   N       Y          1      247500.0  Commercial associate   \n",
              "2      2      M   Y       Y          0      450000.0               Working   \n",
              "3      3      F   N       Y          0      202500.0  Commercial associate   \n",
              "4      4      F   Y       Y          0      157500.0         State servant   \n",
              "\n",
              "                        edu_type     family_type           house_type  \\\n",
              "0               Higher education         Married  Municipal apartment   \n",
              "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
              "2               Higher education         Married    House / apartment   \n",
              "3  Secondary / secondary special         Married    House / apartment   \n",
              "4               Higher education         Married    House / apartment   \n",
              "\n",
              "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  work_phone  phone  email  \\\n",
              "0      -13899          -4709           1           0      0      0   \n",
              "1      -11380          -1540           1           0      0      1   \n",
              "2      -19087          -4434           1           0      1      0   \n",
              "3      -15088          -2092           1           0      1      0   \n",
              "4      -15037          -2105           1           0      0      0   \n",
              "\n",
              "    occyp_type  family_size  begin_month  credit  \n",
              "0          NaN          2.0         -6.0     1.0  \n",
              "1     Laborers          3.0         -5.0     1.0  \n",
              "2     Managers          2.0        -22.0     2.0  \n",
              "3  Sales staff          2.0        -37.0     0.0  \n",
              "4     Managers          2.0        -26.0     2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c3d8711-e507-4fd1-962f-2c102dab7018\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>Municipal apartment</td>\n",
              "      <td>-13899</td>\n",
              "      <td>-4709</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-11380</td>\n",
              "      <td>-1540</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19087</td>\n",
              "      <td>-4434</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15088</td>\n",
              "      <td>-2092</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-37.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15037</td>\n",
              "      <td>-2105</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c3d8711-e507-4fd1-962f-2c102dab7018')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c3d8711-e507-4fd1-962f-2c102dab7018 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c3d8711-e507-4fd1-962f-2c102dab7018');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d860c717-1251-46c7-aafc-dc75864bb057\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d860c717-1251-46c7-aafc-dc75864bb057')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d860c717-1251-46c7-aafc-dc75864bb057 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 26457,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7637,\n        \"min\": 0,\n        \"max\": 26456,\n        \"num_unique_values\": 26457,\n        \"samples\": [\n          19980,\n          9136,\n          14905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"car\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"child_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          19,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101878.36799515961,\n        \"min\": 27000.0,\n        \"max\": 1575000.0,\n        \"num_unique_values\": 249,\n        \"samples\": [\n          30150.0,\n          180000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Working\",\n          \"Student\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edu_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Secondary / secondary special\",\n          \"Academic degree\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Civil marriage\",\n          \"Widow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"house_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Municipal apartment\",\n          \"House / apartment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAYS_BIRTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4201,\n        \"min\": -25152,\n        \"max\": -7705,\n        \"num_unique_values\": 6621,\n        \"samples\": [\n          -9373,\n          -17762\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAYS_EMPLOYED\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 137475,\n        \"min\": -15713,\n        \"max\": 365243,\n        \"num_unique_values\": 3470,\n        \"samples\": [\n          -5130,\n          -1547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_MOBIL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_phone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occyp_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"Laborers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9167167287440334,\n        \"min\": 1.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          20.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"begin_month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.55954998507937,\n        \"min\": -60.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          -6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"credit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7022827610456255,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UAyma4HHpJ0",
        "outputId": "6515a985-679e-46e2-9195-439692ab0b4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26457 entries, 0 to 26456\n",
            "Data columns (total 20 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   index          26457 non-null  int64  \n",
            " 1   gender         26457 non-null  object \n",
            " 2   car            26457 non-null  object \n",
            " 3   reality        26457 non-null  object \n",
            " 4   child_num      26457 non-null  int64  \n",
            " 5   income_total   26457 non-null  float64\n",
            " 6   income_type    26457 non-null  object \n",
            " 7   edu_type       26457 non-null  object \n",
            " 8   family_type    26457 non-null  object \n",
            " 9   house_type     26457 non-null  object \n",
            " 10  DAYS_BIRTH     26457 non-null  int64  \n",
            " 11  DAYS_EMPLOYED  26457 non-null  int64  \n",
            " 12  FLAG_MOBIL     26457 non-null  int64  \n",
            " 13  work_phone     26457 non-null  int64  \n",
            " 14  phone          26457 non-null  int64  \n",
            " 15  email          26457 non-null  int64  \n",
            " 16  occyp_type     18286 non-null  object \n",
            " 17  family_size    26457 non-null  float64\n",
            " 18  begin_month    26457 non-null  float64\n",
            " 19  credit         26457 non-null  float64\n",
            "dtypes: float64(4), int64(8), object(8)\n",
            "memory usage: 4.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "hR2I-oq5WHi2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class ModeSpecificNormalization:\n",
        "    def __init__(self, n_modes):\n",
        "        self.n_modes = n_modes\n",
        "        self.models = {}\n",
        "\n",
        "    def fit(self, data, col_idx):\n",
        "        \"\"\"Fit VGM to the specified column data.\"\"\"\n",
        "        col_data = data[:, col_idx].reshape(-1, 1)\n",
        "        gmm = GaussianMixture(n_components=self.n_modes)\n",
        "        gmm.fit(col_data)\n",
        "        self.models[col_idx] = gmm\n",
        "\n",
        "    def transform(self, data):\n",
        "        \"\"\"Transform the data using mode-specific normalization.\"\"\"\n",
        "        transformed_data = []\n",
        "\n",
        "        for col_idx, gmm in self.models.items():\n",
        "            col_data = data[:, col_idx].cpu().numpy().reshape(-1, 1)  # CPU로 이동 후 NumPy 변환\n",
        "            probs = gmm.predict_proba(col_data)\n",
        "            modes = gmm.means_.reshape(-1)\n",
        "            stds = gmm.covariances_.reshape(-1) ** 0.5\n",
        "\n",
        "            mode_idx = torch.tensor(probs.argmax(axis=1), device=device)\n",
        "            # 원-핫 인코딩된 모드 벡터 제외\n",
        "            normalized_values = (col_data.squeeze() - modes[mode_idx.cpu().numpy()]) / stds[mode_idx.cpu().numpy()]\n",
        "\n",
        "            transformed_data.append(torch.tensor(normalized_values, device=device).unsqueeze(1))\n",
        "\n",
        "        transformed_data = torch.cat(transformed_data, dim=1)\n",
        "        return transformed_data\n",
        "\n",
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, noise_dim, condition_dim, output_dim):\n",
        "        super(ConditionalGenerator, self).__init__()\n",
        "        self.fc1 = nn.Linear(noise_dim + condition_dim, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, noise, cond):\n",
        "        x = torch.cat([noise, cond], dim=1)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.drop(x)\n",
        "        x = self.tanh(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, condition_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim + condition_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 1)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        x = torch.cat([x, cond], dim=1)\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# WGAN-GP Loss functions\n",
        "def gradient_penalty(discriminator, real_data, fake_data, conditions):\n",
        "    alpha = torch.rand(real_data.size(0), 1, device=device)\n",
        "    interpolates = (alpha * real_data + (1 - alpha) * fake_data).requires_grad_(True)\n",
        "    disc_interpolates = discriminator(interpolates, conditions)\n",
        "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                    grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
        "                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
        "    return gradient_penalty\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJqIB-MnLxQ8",
        "outputId": "ff7c0757-1b56-45da-8be2-bdd9012d78d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/test.csv')\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/sample_submission.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "continuous_cols = ['income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'family_size', 'begin_month']\n",
        "categorical_cols = ['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type']\n",
        "target_col = 'credit'\n",
        "\n",
        "data = df_train.drop(columns=[target_col])\n",
        "target_data = df_train[target_col]\n",
        "\n",
        "# Impute missing values\n",
        "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
        "data[categorical_cols] = imputer_categorical.fit_transform(data[categorical_cols])\n",
        "df_test[categorical_cols] = imputer_categorical.transform(df_test[categorical_cols])\n",
        "\n",
        "print(data.isna().sum().sum())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "continuous_data = scaler.fit_transform(data[continuous_cols])\n",
        "continuous_data_test = scaler.transform(df_test[continuous_cols])\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "categorical_data = encoder.fit_transform(data[categorical_cols])\n",
        "categorical_data_test = encoder.transform(df_test[categorical_cols])\n",
        "\n",
        "# Prepare the ModeSpecificNormalization\n",
        "normalizer = ModeSpecificNormalization(n_modes=3)\n",
        "for col_idx in range(len(continuous_cols)):\n",
        "    normalizer.fit(continuous_data, col_idx)\n",
        "\n",
        "normalized_data = normalizer.transform(torch.tensor(continuous_data, dtype=torch.float))\n",
        "normalized_data_test = normalizer.transform(torch.tensor(continuous_data_test, dtype=torch.float))\n",
        "\n",
        "# Convert to torch tensors\n",
        "normalized_data = normalized_data.clone().detach().to(device).float()\n",
        "categorical_data = torch.tensor(categorical_data, dtype=torch.float, device=device)\n",
        "combined_data = torch.cat([normalized_data, categorical_data], dim=1).float()\n",
        "\n",
        "normalized_data_test = normalized_data_test.clone().detach().to(device).float()\n",
        "categorical_data_test = torch.tensor(categorical_data_test, dtype=torch.float, device=device)\n",
        "combined_data_test = torch.cat([normalized_data_test, categorical_data_test], dim=1).float()\n",
        "\n",
        "# Prepare conditions\n",
        "conditions = torch.tensor(target_data.values, dtype=torch.long, device=device)\n",
        "conditions = F.one_hot(conditions, num_classes=3).float()\n",
        "\n",
        "print(\"Combined data shape (train):\", combined_data.shape)\n",
        "print(\"Combined data shape (test):\", combined_data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkGKrWHBVzKj",
        "outputId": "1829d81a-b781-445e-aa4d-a0fb4b89947e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Combined data shape (train): torch.Size([26457, 50])\n",
            "Combined data shape (test): torch.Size([10000, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "noise_dim = 10\n",
        "condition_dim = conditions.shape[1]\n",
        "output_dim = combined_data.shape[1]\n",
        "batch_size = 64\n",
        "epochs = 1000\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = ConditionalGenerator(noise_dim, condition_dim, output_dim).to(device)\n",
        "discriminator = Discriminator(output_dim, condition_dim).to(device)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
        "\n",
        "# Compute class sampling weights to handle class imbalance\n",
        "class_counts = target_data.value_counts().sort_index().values\n",
        "class_weights = (1 / class_counts) / np.sum(1 / class_counts)\n",
        "\n",
        "# Extend class weights to match the size of the conditions array\n",
        "condition_weights = class_weights[conditions.argmax(dim=1).cpu().numpy()]\n",
        "condition_weights = condition_weights / condition_weights.sum()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    for _ in range(5):  # Train discriminator more\n",
        "        # Generate fake data\n",
        "        noise = torch.randn(batch_size, noise_dim, device=device)\n",
        "        condition_indices = np.random.choice(len(conditions), size=batch_size, p=condition_weights)\n",
        "        sampled_conditions = conditions[condition_indices]\n",
        "        fake_data = generator(noise, sampled_conditions)\n",
        "\n",
        "        # Real data (replace this with your actual tabular data)\n",
        "        real_data = combined_data[condition_indices]\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        real_output = discriminator(real_data, sampled_conditions)\n",
        "        fake_output = discriminator(fake_data.detach(), sampled_conditions)\n",
        "\n",
        "        d_loss_real = -torch.mean(real_output)\n",
        "        d_loss_fake = torch.mean(fake_output)\n",
        "\n",
        "        gp = gradient_penalty(discriminator, real_data, fake_data, sampled_conditions)\n",
        "        d_loss = d_loss_real + d_loss_fake + gp\n",
        "\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizer_d.step()\n",
        "\n",
        "    # Train Generator\n",
        "    noise = torch.randn(batch_size, noise_dim, device=device)\n",
        "    condition_indices = np.random.choice(len(conditions), size=batch_size, p=condition_weights)\n",
        "    sampled_conditions = conditions[condition_indices]\n",
        "    fake_data = generator(noise, sampled_conditions)\n",
        "\n",
        "    optimizer_g.zero_grad()\n",
        "    fake_output = discriminator(fake_data, sampled_conditions)\n",
        "    g_loss = -torch.mean(fake_output)\n",
        "\n",
        "    g_loss.backward()\n",
        "    optimizer_g.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch}/{epochs}], d_loss: {d_loss.item()}, g_loss: {g_loss.item()}')\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFEPXuUtV1__",
        "outputId": "357e4f35-ce45-4748-d490-7398099d91b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1000], d_loss: 7.476580619812012, g_loss: 0.019571388140320778\n",
            "Epoch [100/1000], d_loss: -0.45576077699661255, g_loss: -1.0589337348937988\n",
            "Epoch [200/1000], d_loss: -0.571284830570221, g_loss: -0.15224477648735046\n",
            "Epoch [300/1000], d_loss: -0.5501803755760193, g_loss: 0.08545323461294174\n",
            "Epoch [400/1000], d_loss: -0.39934515953063965, g_loss: 0.03738342970609665\n",
            "Epoch [500/1000], d_loss: -0.40719279646873474, g_loss: -0.17261779308319092\n",
            "Epoch [600/1000], d_loss: -0.4385802149772644, g_loss: -0.32440847158432007\n",
            "Epoch [700/1000], d_loss: -0.46238023042678833, g_loss: -0.29440826177597046\n",
            "Epoch [800/1000], d_loss: -0.5487584471702576, g_loss: -0.19212721288204193\n",
            "Epoch [900/1000], d_loss: -0.47673773765563965, g_loss: -0.31255751848220825\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator and discriminator\n",
        "generator = ConditionalGenerator(noise_dim, condition_dim, output_dim).to(device)\n",
        "discriminator = Discriminator(output_dim, condition_dim).to(device)\n",
        "\n",
        "# 생성된 데이터 샘플링 함수\n",
        "def generate_samples(generator, num_samples, noise_dim, condition_dim, device):\n",
        "    noise = torch.randn(num_samples, noise_dim, device=device)\n",
        "    # 조건부 벡터를 원-핫 인코딩된 형태로 생성\n",
        "    condition_indices = torch.randint(0, condition_dim, (num_samples,), device=device)\n",
        "    conditions = F.one_hot(condition_indices, num_classes=condition_dim).float()\n",
        "    with torch.no_grad():\n",
        "        samples = generator(noise, conditions)\n",
        "    # category_indices를 numpy 배열로 변환하여 샘플의 마지막 열로 추가\n",
        "    category_indices = condition_indices.cpu().numpy().reshape(-1, 1)\n",
        "    samples = samples.cpu().numpy()\n",
        "    # 기존 샘플에 조건부 벡터 추가\n",
        "    samples_with_labels = np.hstack((samples, category_indices))\n",
        "    return samples_with_labels\n",
        "\n",
        "# 샘플 생성\n",
        "num_samples = 10\n",
        "generated_samples = generate_samples(generator, num_samples, noise_dim, condition_dim, device)\n",
        "\n",
        "print(\"Generated samples shape:\", generated_samples.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOB-HZisJcs8",
        "outputId": "46831d59-293e-4ee2-f3dc-b5abcfcbbee2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated samples shape: (10, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Normal, Categorical\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.relu(self.fc1(x))\n",
        "        h2 = self.relu(self.fc2(h1))\n",
        "        mu = self.fc_mu(h2)\n",
        "        logvar = self.fc_logvar(h2)\n",
        "        return mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim_cont, output_dim_cat):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Continuous variables\n",
        "        self.fc_mu = nn.Linear(hidden_dim, output_dim_cont)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, output_dim_cont)\n",
        "\n",
        "        # Categorical variables\n",
        "        self.fc_alpha = nn.Linear(hidden_dim, output_dim_cat)\n",
        "        self.fc_beta = nn.Linear(hidden_dim, output_dim_cat)\n",
        "        self.fc_delta = nn.Linear(hidden_dim, output_dim_cat)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        h1 = self.relu(self.fc1(z))\n",
        "        h2 = self.relu(self.fc2(h1))\n",
        "\n",
        "        # Continuous\n",
        "        mu_cont = self.fc_mu(h2)\n",
        "        logvar_cont = self.fc_logvar(h2)\n",
        "\n",
        "        # Categorical\n",
        "        alpha = self.tanh(self.fc_alpha(h2))\n",
        "        beta = self.softmax(self.fc_beta(h2))\n",
        "        delta = self.softmax(self.fc_delta(h2))\n",
        "\n",
        "        return mu_cont, logvar_cont, alpha, beta, delta\n",
        "\n",
        "class TVAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, output_dim_cont, output_dim_cat):\n",
        "        super(TVAE, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, hidden_dim)\n",
        "        self.decoder = Decoder(latent_dim, hidden_dim, output_dim_cont, output_dim_cat)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        mu_cont, logvar_cont, alpha, beta, delta = self.decoder(z)\n",
        "        return mu_cont, logvar_cont, alpha, beta, delta, mu, logvar\n",
        "\n",
        "def loss_function(recon_x_cont, x_cont, recon_alpha, x_alpha, recon_beta, x_beta, mu, logvar):\n",
        "    # Reconstruction loss for continuous variables\n",
        "    recon_loss_cont = nn.functional.mse_loss(recon_x_cont, x_cont, reduction='sum')\n",
        "\n",
        "    # Reconstruction loss for categorical variables\n",
        "    recon_loss_alpha = nn.functional.cross_entropy(recon_alpha, x_alpha, reduction='sum')\n",
        "    recon_loss_beta = nn.functional.cross_entropy(recon_beta, x_beta, reduction='sum')\n",
        "\n",
        "    # KL divergence loss\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return recon_loss_cont + recon_loss_alpha + recon_loss_beta + kld_loss\n",
        "\n",
        "def train(model, data_loader, epochs, learning_rate):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x_cont, x_alpha, x_beta = batch\n",
        "            recon_x_cont, logvar_cont, recon_alpha, recon_beta, recon_delta, mu, logvar = model(x_cont)\n",
        "\n",
        "            loss = loss_function(recon_x_cont, x_cont, recon_alpha, x_alpha, recon_beta, x_beta, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(data_loader.dataset)}')\n"
      ],
      "metadata": {
        "id": "bAAgwzUpNvSp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the dataset\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/test.csv')\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/235713_신용카드 사용자 연체 예측 AI 경진대회_data/open/sample_submission.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "continuous_cols = ['income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'family_size', 'begin_month']\n",
        "categorical_cols = ['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type']\n",
        "target_col = 'credit'\n",
        "\n",
        "data = df_train.drop(columns=[target_col])\n",
        "target_data = df_train[target_col]\n",
        "\n",
        "# Impute missing values\n",
        "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
        "data[categorical_cols] = imputer_categorical.fit_transform(data[categorical_cols])\n",
        "df_test[categorical_cols] = imputer_categorical.transform(df_test[categorical_cols])\n",
        "\n",
        "print(data.isna().sum().sum())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "continuous_data = scaler.fit_transform(data[continuous_cols])\n",
        "continuous_data_test = scaler.transform(df_test[continuous_cols])\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "categorical_data = encoder.fit_transform(data[categorical_cols])\n",
        "categorical_data_test = encoder.transform(df_test[categorical_cols])\n",
        "\n",
        "# Convert to torch tensors\n",
        "continuous_data = torch.tensor(continuous_data, dtype=torch.float, device=device)\n",
        "categorical_data = torch.tensor(categorical_data, dtype=torch.float, device=device)\n",
        "combined_data = torch.cat([continuous_data, categorical_data], dim=1).float()\n",
        "\n",
        "continuous_data_test = torch.tensor(continuous_data_test, dtype=torch.float, device=device)\n",
        "categorical_data_test = torch.tensor(categorical_data_test, dtype=torch.float, device=device)\n",
        "combined_data_test = torch.cat([continuous_data_test, categorical_data_test], dim=1).float()\n",
        "\n",
        "# Prepare conditions\n",
        "conditions = torch.tensor(target_data.values, dtype=torch.long, device=device)\n",
        "conditions = F.one_hot(conditions, num_classes=3).float()\n",
        "\n",
        "print(\"Combined data shape (train):\", combined_data.shape)\n",
        "print(\"Combined data shape (test):\", combined_data_test.shape)\n",
        "\n",
        "# Custom Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, conditions):\n",
        "        self.data = data\n",
        "        self.conditions = conditions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.conditions[idx]\n",
        "\n",
        "train_dataset = CustomDataset(combined_data, conditions)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define Encoder and Decoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.relu(self.fc1(x))\n",
        "        h2 = self.relu(self.fc2(h1))\n",
        "        mu = self.fc_mu(h2)\n",
        "        logvar = self.fc_logvar(h2)\n",
        "        return mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim_cont, output_dim_cat):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Continuous variables\n",
        "        self.fc_mu = nn.Linear(hidden_dim, output_dim_cont)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, output_dim_cont)\n",
        "\n",
        "        # Categorical variables\n",
        "        self.fc_cat = nn.Linear(hidden_dim, output_dim_cat)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        h1 = self.relu(self.fc1(z))\n",
        "        h2 = self.relu(self.fc2(h1))\n",
        "\n",
        "        # Continuous\n",
        "        mu_cont = self.fc_mu(h2)\n",
        "        logvar_cont = self.fc_logvar(h2)\n",
        "\n",
        "        # Categorical\n",
        "        cat_logits = self.fc_cat(h2)\n",
        "\n",
        "        return mu_cont, logvar_cont, cat_logits\n",
        "\n",
        "\n",
        "class TVAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, output_dim_cont, output_dim_cat):\n",
        "        super(TVAE, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
        "        self.decoder = Decoder(latent_dim, hidden_dim, output_dim_cont, output_dim_cat)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        mu_cont, logvar_cont, cat_logits = self.decoder(z)\n",
        "        return mu_cont, logvar_cont, cat_logits, mu, logvar\n",
        "\n",
        "\n",
        "def loss_function(recon_x_cont, x_cont, recon_cat, x_cat, mu, logvar):\n",
        "    recon_loss_cont = nn.functional.mse_loss(recon_x_cont, x_cont, reduction='sum')\n",
        "    recon_loss_cat = nn.functional.cross_entropy(recon_cat, x_cat.argmax(dim=1), reduction='sum')\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss_cont + recon_loss_cat + kld_loss\n",
        "\n",
        "\n",
        "\n",
        "def train(model, data_loader, epochs, learning_rate):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            x, conditions = batch\n",
        "            recon_x_cont, logvar_cont, recon_cat, mu, logvar = model(x)\n",
        "            loss = loss_function(recon_x_cont, x[:, :output_dim_cont], recon_cat, x[:, output_dim_cont:], mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(data_loader.dataset)}')\n",
        "\n",
        "input_dim = combined_data.shape[1]  # Should be 50 (5 continuous + 45 categorical)\n",
        "hidden_dim = 128\n",
        "latent_dim = 64\n",
        "output_dim_cont = 5  # Number of continuous features\n",
        "output_dim_cat = 45  # Number of categorical features\n",
        "\n",
        "model = TVAE(input_dim, hidden_dim, latent_dim, output_dim_cont, output_dim_cat).to(device)\n",
        "train(model, train_loader, epochs=10, learning_rate=1e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDDDrl30-nk",
        "outputId": "af4ef936-58f9-49ac-80bf-3d5510d3055a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Combined data shape (train): torch.Size([26457, 50])\n",
            "Combined data shape (test): torch.Size([10000, 50])\n",
            "Epoch 1, Loss: 5.253577198369273\n",
            "Epoch 2, Loss: 4.787064900333191\n",
            "Epoch 3, Loss: 4.541385061063116\n",
            "Epoch 4, Loss: 4.517228416301282\n",
            "Epoch 5, Loss: 4.491863594324801\n",
            "Epoch 6, Loss: 4.5306490596677955\n",
            "Epoch 7, Loss: 4.497359748491693\n",
            "Epoch 8, Loss: 4.489550388259908\n",
            "Epoch 9, Loss: 4.469125096181643\n",
            "Epoch 10, Loss: 4.471826140615735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_data(model, num_samples):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(num_samples, latent_dim).to(device)\n",
        "        mu_cont, logvar_cont, cat_logits = model.decoder(z)\n",
        "\n",
        "        # For continuous variables\n",
        "        std_cont = torch.exp(0.5 * logvar_cont)\n",
        "        eps_cont = torch.randn_like(std_cont)\n",
        "        generated_cont = mu_cont + eps_cont * std_cont\n",
        "\n",
        "        # For categorical variables\n",
        "        generated_cat = cat_logits\n",
        "\n",
        "        # Concatenate all generated data\n",
        "        print(generated_cont.shape, generated_cat.shape)\n",
        "        generated_data = torch.cat([generated_cont, generated_cat], dim=1)\n",
        "\n",
        "        return generated_data.cpu().numpy()\n",
        "\n",
        "# Generate new synthetic data\n",
        "num_samples = 10\n",
        "synthetic_data = generate_synthetic_data(model, num_samples)\n",
        "print(synthetic_data.shape)  # 출력 형태 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-rfscndGr5M",
        "outputId": "c0beb5c7-aa98-4e54-bf40-7c22494a4718"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 5]) torch.Size([10, 45])\n",
            "(10, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUvmqz2uJw0r",
        "outputId": "d8653149-292b-4a69-f4f6-ee9f14978b86"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.93938780e+00,  1.16848552e+00,  3.10837626e-02,\n",
              "         1.25575042e+00, -8.73213828e-01,  4.18477154e+00,\n",
              "         2.29797959e+00, -4.17949982e+01, -4.10353279e+01,\n",
              "        -4.21837196e+01, -3.96843643e+01, -4.08985481e+01,\n",
              "        -4.19957314e+01, -4.11915054e+01, -4.13144608e+01,\n",
              "        -4.02735710e+01, -4.13967628e+01, -4.24532166e+01,\n",
              "        -3.81071777e+01, -4.46095161e+01, -4.07484818e+01,\n",
              "        -3.99831314e+01, -4.16856384e+01, -4.09219360e+01,\n",
              "        -4.02073936e+01, -3.98976898e+01, -3.94478989e+01,\n",
              "        -4.01754456e+01, -4.07278214e+01, -3.97370682e+01,\n",
              "        -3.86423454e+01, -4.16986771e+01, -4.02304802e+01,\n",
              "        -3.96603279e+01, -4.14991226e+01, -4.23510551e+01,\n",
              "        -4.04643326e+01, -4.00885010e+01, -3.96647415e+01,\n",
              "        -4.05934334e+01, -4.16506577e+01, -3.94071503e+01,\n",
              "        -4.11521988e+01, -3.80369225e+01, -4.08037872e+01,\n",
              "        -4.03212280e+01, -4.11377106e+01, -4.19138603e+01,\n",
              "        -4.26980019e+01, -3.98244781e+01],\n",
              "       [ 2.40764469e-02, -1.21706724e-03, -4.12319779e-01,\n",
              "         2.76036084e-01, -8.26847494e-01,  3.25865221e+00,\n",
              "         2.66135049e+00, -3.99771996e+01, -3.93847961e+01,\n",
              "        -4.05509949e+01, -3.80684013e+01, -3.89662781e+01,\n",
              "        -4.04779778e+01, -3.96965866e+01, -3.95089531e+01,\n",
              "        -3.90121727e+01, -3.97097473e+01, -4.02878380e+01,\n",
              "        -3.64981384e+01, -4.25529289e+01, -3.90771408e+01,\n",
              "        -3.83262215e+01, -3.95643272e+01, -3.87392769e+01,\n",
              "        -3.83788681e+01, -3.85674820e+01, -3.72521629e+01,\n",
              "        -3.86436729e+01, -3.87844086e+01, -3.79271965e+01,\n",
              "        -3.68061600e+01, -4.00305138e+01, -3.86035461e+01,\n",
              "        -3.73645020e+01, -3.97985153e+01, -4.04793701e+01,\n",
              "        -3.90057831e+01, -3.87782288e+01, -3.82017288e+01,\n",
              "        -3.89902878e+01, -3.98902397e+01, -3.74683723e+01,\n",
              "        -3.94273148e+01, -3.63266335e+01, -3.89213905e+01,\n",
              "        -3.89394951e+01, -3.91707077e+01, -4.00141869e+01,\n",
              "        -4.10712318e+01, -3.74408607e+01],\n",
              "       [-1.44543123e+00,  1.15574718e+00,  1.11080706e-01,\n",
              "        -2.71607804e+00, -1.13486469e+00,  1.82881141e+00,\n",
              "         1.04475999e+00, -1.81364346e+01, -1.78480663e+01,\n",
              "        -1.83890743e+01, -1.72326622e+01, -1.77148647e+01,\n",
              "        -1.83756676e+01, -1.78948154e+01, -1.79898758e+01,\n",
              "        -1.75363579e+01, -1.79874210e+01, -1.84644337e+01,\n",
              "        -1.65763416e+01, -1.93550968e+01, -1.76628952e+01,\n",
              "        -1.74834747e+01, -1.80306168e+01, -1.77539654e+01,\n",
              "        -1.74938812e+01, -1.73651810e+01, -1.71085110e+01,\n",
              "        -1.75321712e+01, -1.77366180e+01, -1.72716084e+01,\n",
              "        -1.68712959e+01, -1.81899014e+01, -1.75882130e+01,\n",
              "        -1.72186966e+01, -1.80239868e+01, -1.83356724e+01,\n",
              "        -1.76443615e+01, -1.75107918e+01, -1.73103619e+01,\n",
              "        -1.76707325e+01, -1.81804829e+01, -1.71059551e+01,\n",
              "        -1.78940754e+01, -1.66266479e+01, -1.76952724e+01,\n",
              "        -1.76495838e+01, -1.78684940e+01, -1.82557621e+01,\n",
              "        -1.84749660e+01, -1.72133236e+01],\n",
              "       [-1.67973608e-01, -7.01922655e-01, -1.45541668e+00,\n",
              "        -2.07760501e+00,  4.35588092e-01,  2.31167269e+00,\n",
              "         1.27082193e+00, -2.48615036e+01, -2.44228725e+01,\n",
              "        -2.52514343e+01, -2.35815582e+01, -2.43212032e+01,\n",
              "        -2.52309532e+01, -2.45870113e+01, -2.47308693e+01,\n",
              "        -2.40117912e+01, -2.47298317e+01, -2.54008961e+01,\n",
              "        -2.27023125e+01, -2.66337242e+01, -2.42641125e+01,\n",
              "        -2.39500446e+01, -2.47808056e+01, -2.43948689e+01,\n",
              "        -2.40499077e+01, -2.37527218e+01, -2.34854279e+01,\n",
              "        -2.40655041e+01, -2.43756485e+01, -2.36701984e+01,\n",
              "        -2.31423359e+01, -2.50159397e+01, -2.40866985e+01,\n",
              "        -2.37041340e+01, -2.46857166e+01, -2.51945858e+01,\n",
              "        -2.42612362e+01, -2.39237118e+01, -2.37480659e+01,\n",
              "        -2.41835861e+01, -2.50063229e+01, -2.34014072e+01,\n",
              "        -2.45228500e+01, -2.27864227e+01, -2.42890854e+01,\n",
              "        -2.41648998e+01, -2.45796852e+01, -2.52005196e+01,\n",
              "        -2.53794823e+01, -2.36564693e+01],\n",
              "       [-9.61966872e-01,  1.81480920e+00, -1.80789232e+00,\n",
              "         9.01502669e-01, -2.70754433e+00,  2.02591944e+00,\n",
              "         1.41263390e+00, -2.14422340e+01, -2.11335316e+01,\n",
              "        -2.17260742e+01, -2.04165878e+01, -2.09030132e+01,\n",
              "        -2.16985283e+01, -2.12041740e+01, -2.11948566e+01,\n",
              "        -2.08491516e+01, -2.12508965e+01, -2.16693401e+01,\n",
              "        -1.95954151e+01, -2.28047791e+01, -2.09007454e+01,\n",
              "        -2.06160870e+01, -2.12356853e+01, -2.08490219e+01,\n",
              "        -2.05982285e+01, -2.06382427e+01, -2.00783634e+01,\n",
              "        -2.07127132e+01, -2.08507004e+01, -2.03805885e+01,\n",
              "        -1.98284016e+01, -2.14498806e+01, -2.07565727e+01,\n",
              "        -2.01399727e+01, -2.13392296e+01, -2.16689339e+01,\n",
              "        -2.08597431e+01, -2.07912998e+01, -2.04702091e+01,\n",
              "        -2.09210949e+01, -2.14024773e+01, -2.01763935e+01,\n",
              "        -2.11540546e+01, -1.95658569e+01, -2.08817425e+01,\n",
              "        -2.08902054e+01, -2.10238876e+01, -2.14380016e+01,\n",
              "        -2.19192314e+01, -2.01775570e+01],\n",
              "       [-8.27839077e-01,  7.77827024e-01, -7.49253869e-01,\n",
              "        -2.32005537e-01,  1.63370001e+00,  2.02675009e+00,\n",
              "         1.53482580e+00, -2.17015572e+01, -2.14107170e+01,\n",
              "        -2.19746532e+01, -2.06892662e+01, -2.11315556e+01,\n",
              "        -2.19421234e+01, -2.14709415e+01, -2.14067764e+01,\n",
              "        -2.11561737e+01, -2.14884148e+01, -2.18462963e+01,\n",
              "        -1.98350716e+01, -2.30287762e+01, -2.11521683e+01,\n",
              "        -2.08450584e+01, -2.14460011e+01, -2.10302410e+01,\n",
              "        -2.07987232e+01, -2.09434090e+01, -2.02514191e+01,\n",
              "        -2.09509392e+01, -2.10406647e+01, -2.06112633e+01,\n",
              "        -2.00147457e+01, -2.16709080e+01, -2.09956417e+01,\n",
              "        -2.02721691e+01, -2.16140442e+01, -2.19164753e+01,\n",
              "        -2.10984364e+01, -2.10952225e+01, -2.07163773e+01,\n",
              "        -2.11938381e+01, -2.16067524e+01, -2.04084644e+01,\n",
              "        -2.14103336e+01, -1.97641735e+01, -2.11117802e+01,\n",
              "        -2.11582012e+01, -2.12192154e+01, -2.16034565e+01,\n",
              "        -2.22076836e+01, -2.03362942e+01],\n",
              "       [ 8.43833089e-02, -1.74823844e+00,  2.85745406e+00,\n",
              "        -1.68439376e+00,  4.51913714e-01,  6.83728600e+00,\n",
              "         3.72400832e+00, -6.20207520e+01, -6.08957710e+01,\n",
              "        -6.22070770e+01, -5.89693069e+01, -6.06826324e+01,\n",
              "        -6.17307053e+01, -6.08672600e+01, -6.09178352e+01,\n",
              "        -5.96295357e+01, -6.11302338e+01, -6.26325226e+01,\n",
              "        -5.64923096e+01, -6.59055176e+01, -6.03559532e+01,\n",
              "        -5.89952011e+01, -6.18566628e+01, -6.05967293e+01,\n",
              "        -5.93291664e+01, -5.91770287e+01, -5.85082016e+01,\n",
              "        -5.92186546e+01, -6.00831985e+01, -5.89119186e+01,\n",
              "        -5.70178871e+01, -6.13458748e+01, -5.93869972e+01,\n",
              "        -5.85742111e+01, -6.15927162e+01, -6.27854271e+01,\n",
              "        -5.95489998e+01, -5.93661041e+01, -5.84978828e+01,\n",
              "        -6.01848106e+01, -6.12407722e+01, -5.86267357e+01,\n",
              "        -6.09764175e+01, -5.61215591e+01, -6.04925995e+01,\n",
              "        -5.94542046e+01, -6.07519073e+01, -6.14763718e+01,\n",
              "        -6.33268051e+01, -5.91661034e+01],\n",
              "       [ 1.14090815e-02,  4.18342888e-01, -9.98175859e-01,\n",
              "        -2.08338642e+00,  1.43579912e+00,  1.80061936e+00,\n",
              "         9.80301261e-01, -1.76395245e+01, -1.73523026e+01,\n",
              "        -1.78887711e+01, -1.67518215e+01, -1.72377529e+01,\n",
              "        -1.78778687e+01, -1.73966675e+01, -1.75119972e+01,\n",
              "        -1.70337677e+01, -1.74986877e+01, -1.79899960e+01,\n",
              "        -1.61222534e+01, -1.88411350e+01, -1.71764507e+01,\n",
              "        -1.70142422e+01, -1.75528812e+01, -1.72947769e+01,\n",
              "        -1.70314770e+01, -1.68684406e+01, -1.66679821e+01,\n",
              "        -1.70551968e+01, -1.72738571e+01, -1.68055801e+01,\n",
              "        -1.64312801e+01, -1.77032852e+01, -1.71128922e+01,\n",
              "        -1.67891045e+01, -1.75242081e+01, -1.78360023e+01,\n",
              "        -1.71623707e+01, -1.70131111e+01, -1.68355560e+01,\n",
              "        -1.71804104e+01, -1.77009277e+01, -1.66452866e+01,\n",
              "        -1.74039993e+01, -1.61880074e+01, -1.72182560e+01,\n",
              "        -1.71611176e+01, -1.73993149e+01, -1.77856884e+01,\n",
              "        -1.79554501e+01, -1.67749996e+01],\n",
              "       [ 1.54362634e-01,  1.21294856e-02, -7.85934806e-01,\n",
              "         1.33036387e+00, -8.29406440e-01,  1.73942232e+00,\n",
              "         1.27207601e+00, -1.74389591e+01, -1.72184563e+01,\n",
              "        -1.76419220e+01, -1.66357708e+01, -1.69717999e+01,\n",
              "        -1.76188354e+01, -1.72200089e+01, -1.71846371e+01,\n",
              "        -1.69914551e+01, -1.72384853e+01, -1.75450058e+01,\n",
              "        -1.59485893e+01, -1.84749775e+01, -1.69713631e+01,\n",
              "        -1.67677670e+01, -1.72200966e+01, -1.68997993e+01,\n",
              "        -1.66983414e+01, -1.68327847e+01, -1.62861805e+01,\n",
              "        -1.68242989e+01, -1.69021282e+01, -1.65725079e+01,\n",
              "        -1.60983276e+01, -1.73887272e+01, -1.68887882e+01,\n",
              "        -1.62855663e+01, -1.73727131e+01, -1.75868778e+01,\n",
              "        -1.69217415e+01, -1.69708500e+01, -1.66381054e+01,\n",
              "        -1.70430069e+01, -1.73423271e+01, -1.64294243e+01,\n",
              "        -1.72080669e+01, -1.59011583e+01, -1.69578819e+01,\n",
              "        -1.70109062e+01, -1.70322227e+01, -1.73093529e+01,\n",
              "        -1.78079662e+01, -1.63468380e+01],\n",
              "       [-4.67736602e-01, -8.30646634e-01, -2.39072263e-01,\n",
              "        -1.65448523e+00, -7.81909049e-01,  2.79465270e+00,\n",
              "         1.55451095e+00, -3.17053261e+01, -3.11249599e+01,\n",
              "        -3.22273903e+01, -3.00557346e+01, -3.10318165e+01,\n",
              "        -3.21974869e+01, -3.14014988e+01, -3.15682011e+01,\n",
              "        -3.06286678e+01, -3.15806808e+01, -3.24170609e+01,\n",
              "        -2.89380798e+01, -3.40140915e+01, -3.09804192e+01,\n",
              "        -3.05211716e+01, -3.16265697e+01, -3.11176586e+01,\n",
              "        -3.06969776e+01, -3.02808762e+01, -2.99405231e+01,\n",
              "        -3.07077293e+01, -3.11007004e+01, -3.01741848e+01,\n",
              "        -2.94978924e+01, -3.19425755e+01, -3.06944923e+01,\n",
              "        -3.02483749e+01, -3.14735603e+01, -3.21666069e+01,\n",
              "        -3.09871769e+01, -3.04766445e+01, -3.02984695e+01,\n",
              "        -3.08216591e+01, -3.19248409e+01, -2.98029747e+01,\n",
              "        -3.12689953e+01, -2.90364380e+01, -3.09878826e+01,\n",
              "        -3.08031902e+01, -3.13793907e+01, -3.22195396e+01,\n",
              "        -3.24164162e+01, -3.01709862e+01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQYfftISPeWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}